{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Machine learning Python libraries\n",
    "\n",
    "**Machine learning**\n",
    "\n",
    "''Machine learning is a rapidly growing field of study that involves the development of algorithms and statistical models that enable computers to learn from data and make predictions or decisions without being explicitly programmed. Machine learning techniques are increasingly being used in a variety of applications, from image and speech recognition to natural language processing and autonomous vehicles. As a statistics student, you already have a strong foundation in data analysis and statistical inference, which are crucial skills in machine learning. Through the study of machine learning, you can gain a deeper understanding of how to model complex data and extract useful insights from it, as well as how to design and evaluate algorithms that can learn from this data.''\n",
    "\n",
    "**Note:** this is an introduction lecture on machine learning without exercises or assignments. \n",
    "\n",
    "**Key points:** *algorithms, statistical models, not explicitly programmed, statistical inference*\n",
    "\n",
    "**Learning goals:**\n",
    "\n",
    "- Gain knowledge about the basic capabilities of Python modules `Scikit-learn` and `Keras`\n",
    "- Apply simple regression and classification methods.\n",
    "\n",
    "**Python libraries**\n",
    "\n",
    "- [scikit-learn](https://scikit-learn.org/stable/index.html) \n",
    "    - preprocessing\n",
    "    - classification\n",
    "    - regression\n",
    "    - clustering\n",
    "    - dimensionality reduction\n",
    "    - model selection\n",
    "    - etc. \n",
    "- [Keras](https://keras.io/)\n",
    "    - Demo : simple neural network\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Iris dataset\n",
    "\n",
    "The iris dataset contains 150 samples of iris species, `setosa`, `versicolor` and `virginica` with 50 observations per species. An iris has two features `sepal` and `petal`, see figure below, and for each feature there are the length and width measurements.\n",
    "\n",
    "<img src=\"images/iris1.png\" alt= “” width=\"600\" align='center'>\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "iris = pd.read_csv('data/iris.csv')\n",
    "iris.head()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "iris['class'].value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(1,2,figsize=(10,4))\n",
    "fig.suptitle(\"Iris\")\n",
    "axes[0].set_title(\"Sepal\")\n",
    "axes[1].set_title(\"Petal\")\n",
    "sb.scatterplot(iris, x='sepal_length', y='sepal_width', hue='class',ax=axes[0])\n",
    "sb.scatterplot(iris, x='petal_length', y='petal_width', hue='class',ax=axes[1]);"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Supervised classifier\n",
    "\n",
    "We will build a supervised classifier to predict the species based on the features {sepal, petal} dimensions.\n",
    "\n",
    "### Data preparation\n",
    "\n",
    "- features and target variables\n",
    "- train/test sets\n",
    "- encode variable\n",
    "- standardisation\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Features/target"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "features = iris.columns.drop('class')\n",
    "target = 'class'\n",
    "X, Y = iris[features], iris[target]"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Train/test sets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.40, random_state=42)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "list(map(lambda x : x.shape , [x_train, x_test, y_train, y_test])) # inspect dimensions of train/test variables",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The `train_test_split` function argument `test_size` control the size of the test/train groups and `random_state` is for reproducibility."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Label encoder\n",
    "\n",
    "We need numerical values for the response variable `class`. We can roughly mimic R factors using the Scikit Learn `LabelEncoder` class. The `LabelEncoder` encodes the labels of the target variable with values from the range [0, number of classes -1]. Since our target value has three species of Iris, we'd expect to have the numerical values 0, 1 and 2 after encoding:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()  # class instance\n",
    "le.fit(y_train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "y_train",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The attribute `.classes_` holds the levels present in the training targets:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "le.classes_"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "le.transform(y_train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "We then apply the method `.transform()` on `y_train` and `y_test` separately."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "y_train = le.transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "To encode back use `le.inverse_transform(y_test)`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Feature standardisation\n",
    "In order to perform properly some multivariate models require `standardisation` of the features. The standard score $z = (x-\\mu)/\\sigma$, where $x$ is a feature, $\\mu$ the mean and $\\sigma$ the standard deviation of the training samples. The class `StandardScaler` performs standardisation of all features of the dataset in a one run."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train_st = scaler.transform(x_train)\n",
    "x_test_st = scaler.transform(x_test) "
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "fig, axes = plt.subplots(1,2,figsize=(10,4))\n",
    "fig.suptitle(\"X training set\")\n",
    "axes[0].set_title(\"Raw\")\n",
    "axes[1].set_title(\"Standardised\")\n",
    "sb.kdeplot(x_train, ax=axes[0])\n",
    "sb.kdeplot(x_train_st,ax=axes[1]);"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model : logistic regression\n",
    "\n",
    "We import the class `Linear Regression` from the `linear_model` subsection of the `sklrean`:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(random_state=0)           # model object\n",
    "model.fit(x_train_st, y_train)                       # train the model in the training set\n",
    "y_pred = model.predict(x_test_st)                    # make predictions on the test set"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "(y_test == y_pred).sum()/len(y_test)                 # fraction of correct classifications, i.e. accuracy"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classification quality evaluation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Knowing the values of the predicted classes, we can evaluate the classification with metrics such as `accuracy`:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "See [Metrics](https://scikit-learn.org/stable/modules/model_evaluation.html) for more on prediction quality evaluation."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Cross validation\n",
    "We can see that the accuracy score is quite high, but how can we be sure this is not due to the train/test choice in this instance? Let's repeat the procedure as a function:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def logreg(X, Y, test_size=0.45, random_state=123):\n",
    "    X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(X, Y, test_size=test_size, random_state=random_state) # split train/test\n",
    "    le =LabelEncoder() # encode\n",
    "    le.fit(y_train)\n",
    "    y_train = le.transform(y_train)\n",
    "    y_test = le.transform(y_test)\n",
    "    scaler = StandardScaler() # scaler : standardisation\n",
    "    scaler.fit(X_train)\n",
    "    X_train_st = scaler.transform(X_train)\n",
    "    X_test_st = scaler.transform(X_test)\n",
    "    model = LogisticRegression(random_state=random_state) # model: logistic regression\n",
    "    model.fit(X_train_st, y_train)\n",
    "    y_pred = model.predict(X_test_st) # prediction / accuracy score\n",
    "    return accuracy_score(y_test, y_pred)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "logreg(X,Y,random_state=None)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The resulting accuracy scores differ significantly depending on how the data set is split, which does not allow to evaluate the performance of the model objectively. In practice the problem is solved using *cross-validation*. The basic idea is to repeat the procedure, e.g. `logreg`, and take the mean accuracy.  The predefined Scikit learn function `cross_validate()` does exactly that. The main parameters of the function are the `model`, in this case logistic regression, the `full feature set and the target` and `cv` which is the number of iterations to be performed:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "# Standardise the features on the full data set\n",
    "scaler = StandardScaler()\n",
    "full_train = scaler.fit_transform(iris[features])\n",
    "# Encode the label\n",
    "le =LabelEncoder()\n",
    "class_encoded = le.fit_transform(iris['class'])\n",
    "cv = cross_validate(model, full_train, class_encoded, cv=10)\n",
    "cv"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "cv['test_score'].mean()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Hyperparameter tuning - Grid Search"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Trying to solve a quite simple problem of Iris type classification, we were able to achieve a very high accuracy rate by applying a default version of the classifier. But what if the performance quality is not satisfactory? It is possible to improve the model performance with *hyperparameter optimization*. In Scikit learn, such possibility is provided with the class `GridSearchCV`.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Recall the te logistic regression regularisation penalties $L1$ and $L2$ and the *complexity* parameter $\\lambda$. These were used in regression coefficients shrinkage where larger $\\lambda$ means greater shrinkage. With these parameters one could control the models behaviour for better or worse. The function `GridSearchCV` provides the machinery to traverse different settings using a dictionary along with a `cv` parameter for number cross-validation iterations."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "?LogisticRegression"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "From the documentation we can see that the parameter **C** ( $1/\\lambda$ ), has a default value 1, but, in theory can be any value higher than 0. The default value of a penalty norm is an `l2` norm, but there are other choices available, such as: `{'l1', 'l2', 'elasticnet', 'none'}`. In addition, you may choose among difference solvers (optimisation algorithms) such as `lbfgs`, `liblinear` etc. See for more details [Linear Models](https://scikit-learn.org/stable/modules/linear_model.html).\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "gs_params = {'C': [0.001, 0.01, 0.1, 0.5, 1, 2, 5], # C = 1/lambda\n",
    "             'penalty': ['l2'], \n",
    "             'solver' : ['liblinear', 'newton-cg', 'newton-cholesky', 'lbfgs'] }   # add default 'lbfgs'\n",
    "gs = GridSearchCV(model, gs_params, cv=5)\n",
    "gs.fit(full_train, class_encoded)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Using the attribute `.best_params_` we can check which values of the parameters were selected by the `GridSearch` algorithm as optimal:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "gs.best_params_"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The attribute `.best_score_` allows us to check what is the level of the classification accuracy after the best values of model parameters (`best_params_`) have been applied:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Mean cross-validated score of the best_estimator\n",
    "gs.best_score_"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## SVM\n",
    "\n",
    "With scikit-learn framework you can easily switch between models. Here we use support vector machine as another supervised model for classification:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn import svm\n",
    "clf = svm.SVC()\n",
    "clf.fit(x_train_st, y_train)\n",
    "y_pred = clf.predict(x_test_st)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "accuracy_score(y_pred,y_test)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "## k-nearest neighbors"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "neigh = KNeighborsClassifier(n_neighbors=3)\n",
    "neigh.fit(x_train_st,y_train)\n",
    "y_pred = neigh.predict(x_test_st)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "pd.Series(y_pred).value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "pd.Series(y_test).value_counts()"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "accuracy_score(y_test,y_pred)"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
